{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# For number crunching\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "\n",
    "# For visualisation\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns \n",
    "\n",
    "# For prediction \n",
    "import keras\n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "from keras import metrics\n",
    "\n",
    "import networkx as nx\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Misc\n",
    "import itertools as it\n",
    "from itertools import cycle\n",
    "import json \n",
    "import os\n",
    "\n",
    "# Formatting\n",
    "% matplotlib inline\n",
    "\n",
    "sns.set_context('poster')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "current_palette = cycle(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kitchen_AP_mean</th>\n",
       "      <th>Lounge_AP_mean</th>\n",
       "      <th>Study_AP_mean</th>\n",
       "      <th>Upstairs_AP_mean</th>\n",
       "      <th>bath</th>\n",
       "      <th>bed1</th>\n",
       "      <th>bed2</th>\n",
       "      <th>hall</th>\n",
       "      <th>index</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>...</th>\n",
       "      <th>p_stand</th>\n",
       "      <th>t_bend</th>\n",
       "      <th>t_kneel_stand</th>\n",
       "      <th>t_lie_sit</th>\n",
       "      <th>t_sit_lie</th>\n",
       "      <th>t_sit_stand</th>\n",
       "      <th>t_stand_kneel</th>\n",
       "      <th>t_stand_sit</th>\n",
       "      <th>t_straighten</th>\n",
       "      <th>t_turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.400000</td>\n",
       "      <td>-85.20</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-90.384615</td>\n",
       "      <td>-75.45</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-90.80</td>\n",
       "      <td>0.215734</td>\n",
       "      <td>0.046293</td>\n",
       "      <td>0.438427</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-500.000000</td>\n",
       "      <td>-68.90</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-93.00</td>\n",
       "      <td>0.215734</td>\n",
       "      <td>0.046293</td>\n",
       "      <td>0.438427</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kitchen_AP_mean  Lounge_AP_mean  Study_AP_mean  Upstairs_AP_mean      bath  \\\n",
       "0       -73.400000          -85.20         -500.0            -76.75  0.000000   \n",
       "1       -90.384615          -75.45         -500.0            -90.80  0.215734   \n",
       "2      -500.000000          -68.90         -500.0            -93.00  0.215734   \n",
       "\n",
       "       bed1      bed2      hall  index   kitchen   ...    p_stand t_bend  \\\n",
       "0  0.000000  0.000000  0.593548    3.0  0.329032   ...        0.0    0.0   \n",
       "1  0.046293  0.438427  0.032375    5.0  0.002421   ...        0.0    0.0   \n",
       "2  0.046293  0.438427  0.032375    5.0  0.002421   ...        0.5    0.0   \n",
       "\n",
       "  t_kneel_stand  t_lie_sit t_sit_lie  t_sit_stand  t_stand_kneel  t_stand_sit  \\\n",
       "0           0.0        0.0       0.0          0.0            0.0          0.0   \n",
       "1           0.0        0.0       0.0          0.0            0.0          0.0   \n",
       "2           0.0        0.0       0.0          0.0            0.0          0.0   \n",
       "\n",
       "   t_straighten  t_turn  \n",
       "0           0.0     0.0  \n",
       "1           0.0     0.0  \n",
       "2           0.0     0.0  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xy = pd.read_csv('df_xy_with_loc.csv', dtype={'participant': object})\n",
    "df_xy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Kitchen_AP_mean', 'Lounge_AP_mean', 'Study_AP_mean',\n",
       "       'Upstairs_AP_mean', 'bath', 'bed1', 'bed2', 'hall', 'index', 'kitchen',\n",
       "       'living', 'name', 'participant', 'pir_index', 'pir_name', 'stairs',\n",
       "       'start', 'study', 'toilet', 'x_max', 'x_mean', 'x_median', 'x_min',\n",
       "       'x_std', 'y_max', 'y_mean', 'y_median', 'y_min', 'y_std', 'z_max',\n",
       "       'z_mean', 'z_median', 'z_min', 'z_std', 'end', 'a_ascend', 'a_descend',\n",
       "       'a_jump', 'a_loadwalk', 'a_walk', 'p_bent', 'p_kneel', 'p_lie', 'p_sit',\n",
       "       'p_squat', 'p_stand', 't_bend', 't_kneel_stand', 't_lie_sit',\n",
       "       't_sit_lie', 't_sit_stand', 't_stand_kneel', 't_stand_sit',\n",
       "       't_straighten', 't_turn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all participants\n",
    "\n",
    "participants = ['01','02','03','04','05','06','07','08','09','10']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# train_val/test\n",
    "\n",
    "test_participants = np.random.choice(participants, size=int(len(participants) * .20), replace=False)\n",
    "\n",
    "train_participants = np.setdiff1d(np.array(participants), test_participants)\n",
    "\n",
    "# train/val participants\n",
    "\n",
    "val_participants = np.random.choice(train_participants, size=int(len(participants) * .20), replace=False)\n",
    "\n",
    "train6_participants = np.setdiff1d(np.array(train_participants), val_participants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate X_train and Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate training data with users not in the test set\n",
    "# populate holdout test data with users from the test set\n",
    "\n",
    "df_xy_train_val = df_xy[~df_xy['participant'].isin(test_participants)]\n",
    "\n",
    "df_xy_test = df_xy[df_xy['participant'].isin(test_participants)] \n",
    "\n",
    "# train/validation split\n",
    "\n",
    "df_xy_train = df_xy_train_val[~df_xy_train_val['participant'].isin(val_participants)]\n",
    "\n",
    "df_xy_val = df_xy_train_val[df_xy_train_val['participant'].isin(val_participants)]\n",
    "\n",
    "X_train = df_xy_train.drop(['a_ascend', 'a_descend', 'a_jump', 'a_loadwalk', 'a_walk', 'p_bent',\\\n",
    "                            'p_kneel', 'p_lie', 'p_sit', 'p_squat', 'p_stand', 't_bend', 't_kneel_stand',\\\n",
    "                            't_lie_sit', 't_sit_lie', 't_sit_stand', 't_stand_kneel', 't_stand_sit',\\\n",
    "                            't_straighten', 't_turn','name','index','participant','pir_name','start',\\\n",
    "                            'end'],axis=1)\n",
    "\n",
    "y_train = df_xy_train[['a_ascend', 'a_descend', 'a_jump', 'a_loadwalk', 'a_walk', 'p_bent', 'p_kneel',\\\n",
    "                       'p_lie', 'p_sit', 'p_squat', 'p_stand', 't_bend', 't_kneel_stand', 't_lie_sit',\\\n",
    "                       't_sit_lie', 't_sit_stand', 't_stand_kneel', 't_stand_sit',\\\n",
    "                       't_straighten', 't_turn']]\n",
    "\n",
    "X_val = df_xy_val.drop(['a_ascend', 'a_descend', 'a_jump', 'a_loadwalk', 'a_walk', 'p_bent', 'p_kneel',\\\n",
    "                        'p_lie', 'p_sit', 'p_squat', 'p_stand', 't_bend', 't_kneel_stand', 't_lie_sit',\\\n",
    "                        't_sit_lie', 't_sit_stand', 't_stand_kneel', 't_stand_sit', 't_straighten',\\\n",
    "                        't_turn','name','index','participant','pir_name','start','end'],axis=1)\n",
    "\n",
    "y_val = df_xy_val[['a_ascend', 'a_descend', 'a_jump', 'a_loadwalk', 'a_walk', 'p_bent', 'p_kneel',\\\n",
    "                       'p_lie', 'p_sit', 'p_squat', 'p_stand', 't_bend', 't_kneel_stand', 't_lie_sit',\\\n",
    "                       't_sit_lie', 't_sit_stand', 't_stand_kneel', 't_stand_sit',\\\n",
    "                       't_straighten', 't_turn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9448, 29)\n",
      "(9448, 20)\n",
      "(2468, 29)\n",
      "(2468, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_brier_score(given, predicted): \n",
    "    return np.power(given - predicted, 2.0).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(given, predicted, weights): \n",
    "    return np.power(given - predicted, 2.0).dot(weight_vector).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9448 samples, validate on 2468 samples\n",
      "Epoch 1/12\n",
      "9448/9448 [==============================] - 0s 21us/step - loss: 13.3484 - val_loss: 14.1125\n",
      "Epoch 2/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 3/12\n",
      "9448/9448 [==============================] - 0s 15us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 4/12\n",
      "9448/9448 [==============================] - 0s 16us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 5/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 6/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 7/12\n",
      "9448/9448 [==============================] - 0s 15us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 8/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 9/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 10/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 11/12\n",
      "9448/9448 [==============================] - 0s 15us/step - loss: 13.1742 - val_loss: 14.1125\n",
      "Epoch 12/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 13.1742 - val_loss: 14.1125\n"
     ]
    }
   ],
   "source": [
    "output_dim = nb_classes = y_train.shape[1] \n",
    "model = Sequential() \n",
    "model.add(Dense(output_dim, input_dim=X_train.shape[1], activation='softmax')) \n",
    "batch_size = 128 \n",
    "epochs = 12\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy') \n",
    "history = (model.fit(X_train.values, y_train.values, \n",
    "                     batch_size=batch_size, \n",
    "                     epochs=epochs,\n",
    "                     verbose=1, \n",
    "                     validation_data=(X_val.values, y_val.values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val.values)\n",
    "y_true = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6550117774839868"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unweighted_sequential_score = simple_brier_score(y_true, y_pred)\n",
    "unweighted_sequential_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {\n",
    "                    0:1.352985,\n",
    "                    1:1.386846,\n",
    "                    2:1.595874,\n",
    "                    3:1.353187,\n",
    "                    4:0.347784,\n",
    "                    5:0.661082,\n",
    "                    6:1.047236,\n",
    "                    7:0.398865,\n",
    "                    8:0.207586,\n",
    "                    9:1.505783,\n",
    "                    10:0.110181,\n",
    "                    11:1.078033,\n",
    "                    12:1.365604,\n",
    "                    13:1.170241,\n",
    "                    14:1.193364,\n",
    "                    15:1.180370,\n",
    "                    16:1.344149,\n",
    "                    17:1.116838,\n",
    "                    18:1.080839,\n",
    "                    19:0.503152\n",
    "                }\n",
    "\n",
    "weight_vector = [v for v in class_weights.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9448 samples, validate on 2468 samples\n",
      "Epoch 1/12\n",
      "9448/9448 [==============================] - 0s 22us/step - loss: 5.3290 - val_loss: 12.6319\n",
      "Epoch 2/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 3/12\n",
      "9448/9448 [==============================] - 0s 13us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 4/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 5/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 6/12\n",
      "9448/9448 [==============================] - 0s 15us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 7/12\n",
      "9448/9448 [==============================] - 0s 15us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 8/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 9/12\n",
      "9448/9448 [==============================] - 0s 15us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 10/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 11/12\n",
      "9448/9448 [==============================] - 0s 14us/step - loss: 5.3255 - val_loss: 12.6319\n",
      "Epoch 12/12\n",
      "9448/9448 [==============================] - 0s 15us/step - loss: 5.3255 - val_loss: 12.6319\n"
     ]
    }
   ],
   "source": [
    "# now with weighted classes\n",
    "\n",
    "output_dim = nb_classes = y_train.shape[1] \n",
    "wmodel = Sequential() \n",
    "wmodel.add(Dense(output_dim, input_dim=X_train.shape[1], activation='softmax')) \n",
    "batch_size = 128 \n",
    "epochs = 12\n",
    "\n",
    "wmodel.compile(optimizer='sgd', loss='categorical_crossentropy') \n",
    "history = (wmodel.fit(X_train.values, y_train.values, \n",
    "                     batch_size=batch_size, \n",
    "                     epochs=epochs,\n",
    "                     verbose=1, \n",
    "                     validation_data=(X_val.values, y_val.values),\n",
    "                     class_weight=class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_val.values\n",
    "y_pred = wmodel.predict(X_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2754997380880049"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sequential_score = brier_score(y_true, y_pred, weight_vector)\n",
    "weighted_sequential_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 8\n",
    "multirf = MultiOutputRegressor(RandomForestRegressor(max_depth=max_depth, random_state=42))\n",
    "multirf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6016969967758322"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multirf = multirf.predict(X_val)\n",
    "simple_brier_score(y_val, y_multirf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(max_depth=max_depth, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5824893349757798"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rf = rf.predict(X_val)\n",
    "simple_brier_score(y_val, y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score on test set with the KNN model:  0.2947101824329915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\"\"\"\n",
    "Define a simple class that inherits from sklearn.neighbors.NearestNeighbors. \n",
    "We will adjust the fit/predict as necessary\n",
    "\"\"\"\n",
    "class ProbabilisticKNN(NearestNeighbors): \n",
    "    def __init__(self, n_neighbors): \n",
    "        super(ProbabilisticKNN, self).__init__(n_neighbors)\n",
    "        \n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X_train, y_train): \n",
    "        \"\"\"\n",
    "        The fit function requires both X_train and y_train. \n",
    "        See 'The selected model' section above for explanation\n",
    "        \"\"\"\n",
    "        \n",
    "        self.y_train = np.copy(y_train)\n",
    "        \n",
    "        super(ProbabilisticKNN, self).fit(X_train)\n",
    "        \n",
    "    def predict_proba(self, X_val): \n",
    "        \"\"\"\n",
    "        This function finds the k closest instances to the unseen test data, and \n",
    "        averages the train_labels of the closest instances. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Find the nearest neighbors for the test set\n",
    "        test_neighbors = self.kneighbors(X_val, return_distance=False)\n",
    "        \n",
    "        # Average the labels of these for prediction\n",
    "        return np.asarray(\n",
    "            [self.y_train[inds].mean(0) for inds in test_neighbors]\n",
    "        )\n",
    "\n",
    "# Learn the KNN model \n",
    "nn = ProbabilisticKNN(n_neighbors=11)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test instances\n",
    "y_predicted = nn.predict_proba(X_val)\n",
    "\n",
    "knn_brier_score = brier_score(y_val, y_predicted, class_weights)\n",
    "\n",
    "print (\"Brier score on test set with the KNN model: \", knn_brier_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning model for k=  1\n",
      "score=0.48900\n",
      "Learning model for k=  2\n",
      "score=0.39094\n",
      "Learning model for k=  4\n",
      "score=0.33355\n",
      "Learning model for k=  8\n",
      "score=0.30239\n",
      "Learning model for k= 16\n",
      "score=0.28820\n",
      "Learning model for k= 32\n",
      "score=0.28351\n",
      "Learning model for k= 64\n",
      "score=0.28112\n",
      "Learning model for k=128\n",
      "score=0.28015\n"
     ]
    }
   ],
   "source": [
    "brier_scores = []\n",
    "\n",
    "k_range = np.power(2, range(8))\n",
    "for k in k_range: \n",
    "    print (\"Learning model for k={:3d}\".format(k)), \n",
    "    \n",
    "    nn = ProbabilisticKNN(n_neighbors=k)\n",
    "    nn.fit(X_train, y_train)\n",
    "    \n",
    "    predicted = nn.predict_proba(X_val)\n",
    "    \n",
    "    brier_scores.append(brier_score(y_val, predicted, class_weights))\n",
    "    \n",
    "    print (\"score={:.5f}\".format(brier_scores[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
